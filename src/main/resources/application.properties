server.port=8080

# OpenAPI / Swagger UI
springdoc.api-docs.path=/v3/api-docs
springdoc.swagger-ui.path=/swagger-ui.html
springdoc.swagger-ui.operationsSorter=method

# ---------------------------------------------------------------
# LLM Provider Selection
# Choose one: gemini-vertex | gemini-free | ollama
# ---------------------------------------------------------------
llm.provider=ollama

# URL of this app's OpenAPI spec (read at startup to discover all endpoints)
llm.spec-url=http://localhost:8080/v3/api-docs

# Base URL used to execute REST calls after the LLM decides what to call
llm.api-base-url=http://localhost:8080

# ---------------------------------------------------------------
# Gemini Vertex AI (paid - requires Google Cloud project)
# Activate with: llm.provider=gemini-vertex
# Auth: gcloud auth application-default login
# ---------------------------------------------------------------
llm.vertex-project-id=YOUR_GOOGLE_CLOUD_PROJECT_ID
llm.vertex-location=us-central1
llm.vertex-model=gemini-1.5-pro

# ---------------------------------------------------------------
# Gemini Free - Google AI Studio (free tier, API key only)
# Activate with: llm.provider=gemini-free
# Get key at: https://aistudio.google.com/app/apikey
# Free: 15 req/min, 1500 req/day
# ---------------------------------------------------------------
llm.gemini-api-key=YOUR_GEMINI_API_KEY
llm.gemini-model=gemini-1.5-flash

# ---------------------------------------------------------------
# Ollama (fully local, free, no API key)
# Activate with: llm.provider=ollama
# Install: https://ollama.com
# Then run: ollama pull llama3.1
# Models with function calling: llama3.1, llama3.2, qwen2.5, mistral
# ---------------------------------------------------------------
llm.ollama-base-url=http://localhost:11434
llm.ollama-model=llama3.1
